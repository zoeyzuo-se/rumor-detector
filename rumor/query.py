# scripts/query.py
from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings
from langchain.chains import RetrievalQA
from config import *
from langchain_community.vectorstores import AzureSearch
from config import *


def main():
    # ç”¨æˆ·è¾“å…¥å†…å®¹
    query = input("è¯·è¾“å…¥ä½ æƒ³é‰´åˆ«çš„è¯ï¼ˆå¦‚ï¼šè½¬å‘è¿™æ¡è§†é¢‘èƒ½è¾Ÿé‚ªï¼‰ï¼š\n> ")

    # åµŒå…¥æ¨¡å‹
    embeddings = AzureOpenAIEmbeddings(
        model=EMBEDDING_DEPLOYMENT_NAME,
        azure_endpoint=AZURE_OPENAI_ENDPOINT,
        api_key=AZURE_OPENAI_API_KEY,
        openai_api_version=EMBEDDING_API_VERSION,
    )

    # åˆå§‹åŒ– Azure Search å‘é‡åº“
    vectorstore = AzureSearch(
        azure_search_endpoint=AZURE_SEARCH_ENDPOINT,
        azure_search_key=AZURE_SEARCH_API_KEY,
        index_name=AZURE_SEARCH_INDEX_NAME,
        embedding_function=embeddings,
    )

    # æ„å»º QA Chain
    retriever = vectorstore.as_retriever(search_type="similarity", k=3)

    # vectorstore = FAISS.load_local("faiss_index", embeddings, allow_dangerous_deserialization=True)

    print("ğŸ§  Initializing GPT model...")
    # åˆå§‹åŒ– GPT æ¨¡å‹
    llm = AzureChatOpenAI(
        azure_deployment="gpt-4",  # éƒ¨ç½²çš„ GPT æ¨¡å‹åå­—
        azure_endpoint=AZURE_OPENAI_ENDPOINT,
        api_key=AZURE_OPENAI_API_KEY,
        api_version="2024-12-01-preview"
    )

    # æ„å»ºé—®ç­”é“¾
    print("ğŸ”— Building RetrievalQA chain...")
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=retriever,  # Use retrieved docs directly
        chain_type="stuff",
        return_source_documents=True
    )

    # æ‰§è¡ŒæŸ¥è¯¢
    result = qa_chain.invoke({"query": query})
    print("\nğŸ“¢ å›ç­”ï¼š")
    print(result["result"])

    # print("\nğŸ“š å‚è€ƒå†…å®¹ç‰‡æ®µï¼š")
    # for doc in result["source_documents"]:
    #     print(f"---\n{doc.page_content.strip()}")

if __name__ == "__main__":
    main()
